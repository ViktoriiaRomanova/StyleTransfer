{"cells":[{"cell_type":"markdown","id":"dbc1b04a","metadata":{"cellId":"1l1hryljby209z02qr69m","execution_id":"45b2034a-7546-4164-8adc-3ff7b65179c6","id":"dbc1b04a"},"source":["# Style Transfer (pretrained model)"]},{"cell_type":"markdown","id":"27304533","metadata":{"cellId":"t01cptmmqvaxspclmb8ge","execution_id":"e967c779-c514-43b7-b0cb-e560abff2c75","id":"27304533"},"source":["#### Import dependencies"]},{"cell_type":"code","execution_count":null,"id":"4ba412d8","metadata":{"cellId":"ie845bomfw6egxernk9v5","id":"4ba412d8"},"outputs":[],"source":["#!g1.1 #noqa\n","import urllib.request\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","from PIL import Image\n","from torch import nn\n","from torch import optim\n","from torch.optim.lr_scheduler import StepLR\n","from torchsummary import summary\n","from torchvision import transforms\n","from torchvision.models import vgg19_bn, VGG19_BN_Weights\n","from torchvision.models.feature_extraction import create_feature_extractor"]},{"cell_type":"code","execution_count":null,"id":"055cfa2c","metadata":{"cellId":"saxcaua8ro848iyllnh5rr","id":"055cfa2c"},"outputs":[],"source":["#!g1.1 #noqa\n","!nvidia-smi"]},{"cell_type":"markdown","id":"786345dc","metadata":{"cellId":"vvpsdv294ptkvxipbt1h","execution_id":"5ce899ad-a00d-462a-b0f4-ea327c4cb7ba","id":"786345dc"},"source":["#### Seting seed and device"]},{"cell_type":"code","execution_count":null,"id":"d8e48461","metadata":{"cellId":"hjlazyo1taafxl4vxe50m7","id":"d8e48461"},"outputs":[],"source":["#!g1.1 #noqa\n","random_seed = 10\n","torch.manual_seed(random_seed)\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"markdown","id":"eb9dedb5","metadata":{"cellId":"8tifamlosbwpanxa2uh65j","execution_id":"99cc8a25-6a1a-4936-9b56-939f5c56679c","id":"eb9dedb5"},"source":["### Model"]},{"cell_type":"markdown","id":"7799ed0d","metadata":{"cellId":"f9fsp290z0t1c8pxixvir4","execution_id":"86ff80d3-7921-4ca8-9102-e0998d47c10f","id":"7799ed0d"},"source":["Get pretraind veights and save them localy(to exclude downloding every time)"]},{"cell_type":"code","execution_count":null,"id":"7ff95ef5","metadata":{"cellId":"pvrkejookarv601imq6pac","id":"7ff95ef5"},"outputs":[],"source":["#!g1.1 #noqa\n","# Skip this part if you already have downloaded weights\n","weights = VGG19_BN_Weights.DEFAULT\n","model = vgg19_bn(weights = weights).features\n","torch.save(model.state_dict(), 'vgg19_bn_weights.pt')"]},{"cell_type":"markdown","id":"6317d564","metadata":{"cellId":"xck2gladom5nauaeccso6","execution_id":"48d9e8c6-2ff7-40c0-b211-81c6f196ac65","id":"6317d564"},"source":["Loading convolutional part of the model architecture (without classifier)"]},{"cell_type":"code","execution_count":null,"id":"eedb8d05","metadata":{"cellId":"3pfxi28ut31ula7htwtuld","id":"eedb8d05"},"outputs":[],"source":["#!g1.1 #noqa\n","model = vgg19_bn(weights=None).features.to(device)"]},{"cell_type":"markdown","id":"03637eff","metadata":{"cellId":"a6o6dq8qgqjzu7hn3xwc2d","execution_id":"a09a6a12-ad27-471e-b7f6-482d062c27af","id":"03637eff"},"source":["Replace pooling layers into AvgPool (based on the article [How to Get Beautiful Results with Neural Style Transfer](https://towardsdatascience.com/how-to-get-beautiful-results-with-neural-style-transfer-75d0c05d6489))"]},{"cell_type":"code","execution_count":null,"id":"1d65dad1","metadata":{"cellId":"frte8azt53f14fk5tcrq3","id":"1d65dad1"},"outputs":[],"source":["#!g1.1 #noqa\n","for i in range(len(model)):\n","    if model[i].__class__.__name__ == 'MaxPool2d':\n","        model[i] = nn.AvgPool2d(kernel_size=2, stride=2, padding=0, ceil_mode=False)"]},{"cell_type":"code","execution_count":null,"id":"79a17312","metadata":{"cellId":"g9ylb09iypp6vst1akrgg","id":"79a17312"},"outputs":[],"source":["#!g1.1 #noqa\n","model.load_state_dict(torch.load('vgg19_bn_weights.pt', map_location = device))"]},{"cell_type":"code","execution_count":null,"id":"a1328d4b","metadata":{"cellId":"sqk2y7ersj8emkmttltpes","id":"a1328d4b"},"outputs":[],"source":["#!g1.1 #noqa\n","summary(model, (3, 224, 224), device = device)"]},{"cell_type":"markdown","id":"4bc6fc29","metadata":{"cellId":"eq2cwvg80nj0axkz089lvp","execution_id":"3414cf78-9490-4960-99f6-77affc5b1280","id":"4bc6fc29"},"source":["### Data preparation"]},{"cell_type":"markdown","id":"929d188e","metadata":{"cellId":"rj1ta8qf6iszkve8kwz0e","execution_id":"abc079cb-90c2-4904-8155-92e0708ca662","id":"929d188e"},"source":["Getting style image and save it locally"]},{"cell_type":"code","execution_count":null,"id":"6b0ccd9b","metadata":{"cellId":"525twhvje8t6n5sj1e6z1s","execution_id":"bccdb41c-c000-414a-8ef4-20ec5fa4a42f","id":"6b0ccd9b"},"outputs":[],"source":["#!g1.1 #noqa\n","urllib.request.urlretrieve('https://path_to_your_img.jpg', 'style.jpg')"]},{"cell_type":"code","execution_count":null,"id":"8c836a2b","metadata":{"cellId":"p1simx3pwmdebho8s1gj8i","id":"8c836a2b"},"outputs":[],"source":["#!g1.1 #noqa\n","def load_image(path: str) -> torch.tensor:\n","    \"\"\"Open, resize and normalize image.\"\"\"\n","    img = Image.open(path)\n","\n","    transformation = transforms.Compose([\n","        transforms.Resize([224, 224]),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","    ])\n","    img = transformation(img)\n","    return img"]},{"cell_type":"code","execution_count":null,"id":"d9e35286","metadata":{"cellId":"ev6r4m3p8lft3d5bp553","id":"d9e35286"},"outputs":[],"source":["#!g1.1 #noqa\n","content = load_image('./image/content/test1.jpg').to(device)\n","style = load_image('./image/style/test_2.jpg').to(device)"]},{"cell_type":"code","execution_count":null,"id":"ef5b197b","metadata":{"cellId":"mhgaljt0n5rloc8v3yue","id":"ef5b197b"},"outputs":[],"source":["#!g1.1 #noqa\n","def conv_to_img(tensor: torch.tensor) -> np.array:\n","    \"\"\"Convert tensor back to image.\"\"\"\n","    img = tensor.to('cpu').clone().detach()\n","    img = img.numpy().squeeze()\n","    img = img.transpose(1, 2, 0)\n","    img = img * np.array((0.229, 0.224, 0.225)) + np.array((0.485, 0.456, 0.406))\n","    img = img.clip(0, 1)\n","    return img"]},{"cell_type":"markdown","id":"f05ae9ef","metadata":{"cellId":"6whu5aoq47w43xpt1i3ph9","execution_id":"e11e639f-0e8b-4261-badd-6fc1822791c3","id":"f05ae9ef"},"source":["Let's look at our images"]},{"cell_type":"code","execution_count":null,"id":"1238190e","metadata":{"cellId":"zdnsy38if35vdunh2atm","id":"1238190e"},"outputs":[],"source":["#!g1.1 #noqa\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 20))\n","ax1.imshow(conv_to_img(content))\n","ax1.set_title('Content image')\n","ax2.imshow(conv_to_img(style))\n","ax2.set_title('Style image')\n","plt.show()"]},{"cell_type":"markdown","id":"e4bf8bd5","metadata":{"cellId":"pmpht0tlqrmfcwtasxbqos","execution_id":"b4e11a31-ed0d-4a03-8c2d-0349e28fbc4c","id":"e4bf8bd5"},"source":[" ### Getting intermediate nodes(features) from the given model"]},{"cell_type":"code","execution_count":null,"id":"5d3595f2","metadata":{"cellId":"74ytwdlz36dnvpmvtpku5","id":"5d3595f2"},"outputs":[],"source":["#!g1.1 #noqa\n","features = create_feature_extractor(model, return_nodes = ['2', '9', '12', '22', '29', '42'])"]},{"cell_type":"markdown","id":"3226bde9","metadata":{"cellId":"6ypq1787yo3mbowe3meau","execution_id":"e9e916a9-14c4-4029-87e2-d7c78972f5e0","id":"3226bde9"},"source":["For better understanding what is important for the model at each picked layer let's have a look at some of them."]},{"cell_type":"code","execution_count":null,"id":"cfd3e00b","metadata":{"cellId":"bb7mtpqst5rhlqexo0x9x9","id":"cfd3e00b"},"outputs":[],"source":["#!g1.1 #noqa\n","style_features = features(style.unsqueeze(0).detach())"]},{"cell_type":"code","execution_count":null,"id":"ee362e07","metadata":{"cellId":"oklvn735fgil08l90jkc3","id":"ee362e07"},"outputs":[],"source":["#!g1.1 #noqa\n","style_features['2'].shape"]},{"cell_type":"code","execution_count":null,"id":"b748f545","metadata":{"cellId":"zesv1zpvzok9tna4zpxwn","id":"b748f545"},"outputs":[],"source":["#!g1.1 #noqa\n","fig, ax = plt.subplots(8, 8, figsize=(30, 30))\n","\n","for i, f in enumerate(style_features['2'].squeeze()):\n","\n","    ax[i // 8][i % 8].imshow(f.detach().cpu().numpy())\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"d5a4485e","metadata":{"cellId":"34t0akohxbwds5fke5jps","id":"d5a4485e"},"outputs":[],"source":["#!g1.1 #noqa\n","with torch.no_grad():\n","    content_features = features(content.unsqueeze(0))"]},{"cell_type":"code","execution_count":null,"id":"8a07fd2b","metadata":{"cellId":"q11alqp93wb9w8f67b5pih","id":"8a07fd2b"},"outputs":[],"source":["#!g1.1 #noqa\n","fig, ax = plt.subplots(8, 8, figsize=(30, 30))\n","\n","for i, f in enumerate(content_features['2'].squeeze()[:64]):\n","\n","    ax[i // 8][i % 8].imshow(f.detach().cpu().numpy())\n","\n","plt.show()"]},{"cell_type":"markdown","id":"aae0c00b","metadata":{"cellId":"551mcl7wlggogqm5prumg","execution_id":"94d4e59c-4169-4d62-a4d3-2e735cf0cbc8","id":"aae0c00b"},"source":["### Metrics\n"]},{"cell_type":"code","execution_count":null,"id":"c33a8b6e","metadata":{"cellId":"omxzws8id5h689f6wzgode","id":"c33a8b6e"},"outputs":[],"source":["#!g1.1 #noqa\n","def gram_matrix(tensor: torch.tensor) -> torch.tensor:\n","    \"\"\"Calculate the gram matrix.\"\"\"\n","    _, d, h, w = tensor.size()  # first parameter is batch size, we don't need it\n","    tensor = tensor.view(d, h * w)\n","    gram = torch.mm(tensor, tensor.t())\n","\n","    return gram.div(d * h * w)"]},{"cell_type":"markdown","id":"3e5371b5","metadata":{"cellId":"xlsoeoc6t0h3goge886jq","execution_id":"e78211a2-0c4e-4f68-b979-fd44022c044d","id":"3e5371b5"},"source":["As style image is not changing during the training process, we can calculate its gram matrix just once and use it during the train."]},{"cell_type":"code","execution_count":null,"id":"88adf6c3","metadata":{"cellId":"pd3lyeo34we6frc6qj6k99","id":"88adf6c3"},"outputs":[],"source":["#!g1.1 #noqa\n","style_grams = {layer: gram_matrix(style_features[layer]).detach() for layer in style_features}"]},{"cell_type":"code","execution_count":null,"id":"1abf3895","metadata":{"cellId":"zkq8an4zsyiydtc5ptjgmf","id":"1abf3895"},"outputs":[],"source":["#!g1.1 #noqa\n","# Use content image as a target image\n","target = content.clone().requires_grad_(True).to(device)\n","\n","# Use random noise as a target image\n","# target = torch.rand(content.shape, requires_grad=True, device='cuda')"]},{"cell_type":"code","execution_count":null,"id":"3c65bcf3","metadata":{"cellId":"9zxa3m082j0kztgom8386d","id":"3c65bcf3"},"outputs":[],"source":["#!g1.1 #noqa\n","# Sets influence of each style layer to final loss\n","style_weights = {'2': 1,\n","                 '9': 0.9,\n","                 '12': 0.75,\n","                 '22': 0.2,\n","                 '29': 0.5,\n","                 '42': 0.2}\n","\n","content_weight = 1  # alpha\n","style_weight = 1e9  # beta"]},{"cell_type":"markdown","id":"c6e58990","metadata":{"cellId":"v85k23mdwioki72mrp50a","execution_id":"b5802353-d23b-423f-bf45-8520d881a83e","id":"c6e58990"},"source":["### Setup training process  "]},{"cell_type":"code","execution_count":null,"id":"322762fb","metadata":{"cellId":"ivl7vnwyy2cle9sfugg97","id":"322762fb"},"outputs":[],"source":["#!g1.1 #noqa\n","optimizer = optim.Adam([target], lr=0.05)\n","scheduler = StepLR(optimizer, step_size = 1000, gamma = 0.5)\n","loss_func = nn.L1Loss()\n","epochs = 2000"]},{"cell_type":"code","execution_count":null,"id":"9343ad10","metadata":{"cellId":"26eb5lssir7juc2lam4rl2o","id":"9343ad10"},"outputs":[],"source":["#!g1.1 #noqa\n","for eposh in range(epochs):\n","\n","    # gets the features from the target image\n","    target_img_features = features(target.unsqueeze(0))\n","\n","    # Calculates the content loss\n","    content_loss = loss_func(target_img_features['2'], content_features['2'])\n","\n","    # gets the style loss\n","    style_loss = 0\n","    for layer in style_weights:\n","        # gets the target image style representation at that layer\n","        target_img_feature = target_img_features[layer]\n","\n","        # calculates gram matrix for target image features at that layer\n","        target_img_gram = gram_matrix(target_img_feature)\n","\n","        # gets value of gram matrix for style image features at that layer\n","        style_gram = style_grams[layer]\n","\n","        # calculates weighted style loss for that layer\n","        style_loss += style_weights[layer] * loss_func(target_img_gram, style_gram)\n","\n","    # calculates the total loss\n","    loss = content_weight * content_loss + style_weight * style_loss\n","\n","    # updates target image\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    scheduler.step()\n","\n","    # displays intermediate images and the loss\n","    if (eposh + 1) % 1000 == 0:\n","        plt.title('Loss: {:.3f}'.format(loss.item()))\n","        plt.imshow(conv_to_img(target))\n","        plt.show()"]},{"cell_type":"markdown","id":"32a7a763","metadata":{"cellId":"7zsxi62i23rosrke906e3c","execution_id":"c7e68ad8-2add-4a94-88f3-1280afeea3a6","id":"32a7a763"},"source":["### Compare the results"]},{"cell_type":"code","execution_count":null,"id":"bcd44e8b","metadata":{"cellId":"2ykyfamwjmftedw8rf5qqb","id":"bcd44e8b"},"outputs":[],"source":["#!g1.1 #noqa\n","fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (25, 25))\n","\n","ax1.imshow(conv_to_img(content))\n","ax1.set_title('Content image')\n","ax2.imshow(conv_to_img(style))\n","ax2.set_title('Style image')\n","ax3.imshow(conv_to_img(target))\n","ax3.set_title('Target')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"8af9a414","metadata":{"cellId":"cdwvxrmln3it45369a0bzo","id":"8af9a414"},"outputs":[],"source":["#!g1.1 #noqa\n"]}],"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"notebookId":"e9884db2-486c-4001-b4ba-85380f3da8d5","notebookPath":"TransferLearning/style_trunsfer.ipynb","colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}