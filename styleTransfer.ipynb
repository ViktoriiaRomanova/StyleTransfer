{"cells":[{"cell_type":"markdown","id":"72a6bac9","metadata":{"cellId":"1l1hryljby209z02qr69m","execution_id":"45b2034a-7546-4164-8adc-3ff7b65179c6","id":"72a6bac9"},"source":["# Style Transfer (pretrained model)"]},{"cell_type":"markdown","id":"ef0da8d5","metadata":{"cellId":"t01cptmmqvaxspclmb8ge","execution_id":"e967c779-c514-43b7-b0cb-e560abff2c75","id":"ef0da8d5"},"source":["#### Import dependencies"]},{"cell_type":"code","execution_count":null,"id":"463d2a72","metadata":{"cellId":"ie845bomfw6egxernk9v5","id":"463d2a72"},"outputs":[],"source":["#!g1.1 #noqa\n","import os\n","import urllib.request\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","from PIL import Image\n","from torch import nn\n","from torch import optim\n","from torch.optim.lr_scheduler import StepLR\n","from torchsummary import summary\n","from torchvision import transforms\n","from torchvision.models import vgg19_bn, VGG19_BN_Weights\n","from torchvision.models.feature_extraction import create_feature_extractor"]},{"cell_type":"code","execution_count":null,"id":"d42669f3","metadata":{"cellId":"saxcaua8ro848iyllnh5rr","id":"d42669f3"},"outputs":[],"source":["#!g1.1 #noqa\n","!nvidia-smi"]},{"cell_type":"code","execution_count":null,"id":"b5985ee2","metadata":{"cellId":"h7ijhkhtpdngkxe6vlisp9","id":"b5985ee2"},"outputs":[],"source":["#!g1.1 #noqa\n","MODEL_WEIGHTS_DIR = './models/weights/'\n","IMAGE_DIR = './image/'\n","STYLE_DIR = IMAGE_DIR + 'style/'\n","CONTENT_DIR = IMAGE_DIR + 'content/'"]},{"cell_type":"markdown","id":"de5662c8","metadata":{"cellId":"vvpsdv294ptkvxipbt1h","execution_id":"5ce899ad-a00d-462a-b0f4-ea327c4cb7ba","id":"de5662c8"},"source":["#### Setting seed and device"]},{"cell_type":"code","execution_count":null,"id":"a7ebfdbd","metadata":{"cellId":"hjlazyo1taafxl4vxe50m7","id":"a7ebfdbd"},"outputs":[],"source":["#!g1.1 #noqa\n","random_seed = 10\n","torch.manual_seed(random_seed)\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"markdown","id":"d1646ba6","metadata":{"cellId":"8tifamlosbwpanxa2uh65j","execution_id":"32809d02-4f4a-448f-bdcc-3a7b2518e9c3","id":"d1646ba6"},"source":["### Model"]},{"cell_type":"markdown","id":"74af78b2","metadata":{"cellId":"f9fsp290z0t1c8pxixvir4","execution_id":"acc0575d-4b70-42fa-999c-be14aaf13292","id":"74af78b2"},"source":["Get pretrained weights and save them localy (to exclude downloading every time)"]},{"cell_type":"code","execution_count":null,"id":"af37354e","metadata":{"cellId":"pvrkejookarv601imq6pac","id":"af37354e"},"outputs":[],"source":["#!g1.1 #noqa\n","weights_path = MODEL_WEIGHTS_DIR + 'vgg19_bn_weights.pt'\n","\n","if not os.path.isfile(weights_path):\n","    if not os.path.exists(MODEL_WEIGHTS_DIR):\n","        os.makedirs(MODEL_WEIGHTS_DIR)\n","    weights = VGG19_BN_Weights.DEFAULT\n","    model = vgg19_bn(weights = weights).features\n","    torch.save(model.state_dict(), MODEL_WEIGHTS_DIR + 'vgg19_bn_weights.pt')"]},{"cell_type":"markdown","id":"826b0a7e","metadata":{"cellId":"xck2gladom5nauaeccso6","execution_id":"48d9e8c6-2ff7-40c0-b211-81c6f196ac65","id":"826b0a7e"},"source":["Loading convolutional part of the model architecture (without classifier)"]},{"cell_type":"code","execution_count":null,"id":"6a301dca","metadata":{"cellId":"3pfxi28ut31ula7htwtuld","id":"6a301dca"},"outputs":[],"source":["#!g1.1 #noqa\n","model = vgg19_bn(weights=None).features.to(device)"]},{"cell_type":"markdown","id":"0e63d247","metadata":{"cellId":"a6o6dq8qgqjzu7hn3xwc2d","execution_id":"2b52b2e7-2762-451f-9a29-67a530180a85","id":"0e63d247"},"source":["Replace pooling layers with AvgPool (based on the article [How to Get Beautiful Results with Neural Style Transfer](https://towardsdatascience.com/how-to-get-beautiful-results-with-neural-style-transfer-75d0c05d6489))"]},{"cell_type":"code","execution_count":null,"id":"799847b5","metadata":{"cellId":"frte8azt53f14fk5tcrq3","id":"799847b5"},"outputs":[],"source":["#!g1.1 #noqa\n","for i in range(len(model)):\n","    if model[i].__class__.__name__ == 'MaxPool2d':\n","        model[i] = nn.AvgPool2d(kernel_size=2, stride=2, padding=0, ceil_mode=False)"]},{"cell_type":"code","execution_count":null,"id":"d1ab7928","metadata":{"cellId":"g9ylb09iypp6vst1akrgg","id":"d1ab7928"},"outputs":[],"source":["#!g1.1 #noqa\n","model.load_state_dict(torch.load(weights_path, map_location = device))"]},{"cell_type":"code","execution_count":null,"id":"39407699","metadata":{"cellId":"sqk2y7ersj8emkmttltpes","id":"39407699"},"outputs":[],"source":["#!g1.1 #noqa\n","summary(model, (3, 224, 224), device = device)"]},{"cell_type":"markdown","id":"c610ae62","metadata":{"cellId":"eq2cwvg80nj0axkz089lvp","execution_id":"3414cf78-9490-4960-99f6-77affc5b1280","id":"c610ae62"},"source":["### Data preparation"]},{"cell_type":"markdown","id":"15f203a4","metadata":{"cellId":"rj1ta8qf6iszkve8kwz0e","execution_id":"abc079cb-90c2-4904-8155-92e0708ca662","id":"15f203a4"},"source":["Getting style image and save it locally"]},{"cell_type":"code","execution_count":null,"id":"7ad0feda","metadata":{"cellId":"525twhvje8t6n5sj1e6z1s","execution_id":"bccdb41c-c000-414a-8ef4-20ec5fa4a42f","id":"7ad0feda"},"outputs":[],"source":["#!g1.1 #noqa\n","urllib.request.urlretrieve('https://path_to_your_img.jpg', STYLE_DIR + 'style.jpg')"]},{"cell_type":"code","execution_count":null,"id":"c4b8e835","metadata":{"cellId":"p1simx3pwmdebho8s1gj8i","id":"c4b8e835"},"outputs":[],"source":["#!g1.1 #noqa\n","def load_image(path: str) -> torch.tensor:\n","    \"\"\"Open, resize and normalize image.\"\"\"\n","    img = Image.open(path)\n","\n","    transformation = transforms.Compose([\n","        transforms.Resize([224, 224]),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","    ])\n","    img = transformation(img)\n","    return img"]},{"cell_type":"code","execution_count":null,"id":"a5974d45","metadata":{"cellId":"ev6r4m3p8lft3d5bp553","id":"a5974d45"},"outputs":[],"source":["#!g1.1 #noqa\n","content = load_image(CONTENT_DIR + 'test1.jpg').to(device)\n","style = load_image(STYLE_DIR + 'test_2.jpg').to(device)"]},{"cell_type":"code","execution_count":null,"id":"5c9d67b6","metadata":{"cellId":"mhgaljt0n5rloc8v3yue","id":"5c9d67b6"},"outputs":[],"source":["#!g1.1 #noqa\n","def conv_to_img(tensor: torch.tensor) -> np.array:\n","    \"\"\"Convert tensor back to image.\"\"\"\n","    img = tensor.to('cpu').clone().detach()\n","    img = img.numpy().squeeze()\n","    img = img.transpose(1, 2, 0)\n","    img = img * np.array((0.229, 0.224, 0.225)) + np.array((0.485, 0.456, 0.406))\n","    img = img.clip(0, 1)\n","    return img"]},{"cell_type":"markdown","id":"126bb16a","metadata":{"cellId":"6whu5aoq47w43xpt1i3ph9","execution_id":"d5565968-253b-4387-8b4b-f280be0709fe","id":"126bb16a"},"source":["Let's look at our images"]},{"cell_type":"code","execution_count":null,"id":"890f2ef1","metadata":{"cellId":"zdnsy38if35vdunh2atm","id":"890f2ef1"},"outputs":[],"source":["#!g1.1 #noqa\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 20))\n","ax1.imshow(conv_to_img(content))\n","ax1.set_title('Content image')\n","ax2.imshow(conv_to_img(style))\n","ax2.set_title('Style image')\n","plt.show()"]},{"cell_type":"markdown","id":"9c66ca3c","metadata":{"cellId":"pmpht0tlqrmfcwtasxbqos","execution_id":"23824dcd-bd9b-4a72-8b5f-dcb64f35890b","id":"9c66ca3c"},"source":[" ### Getting intermediate nodes (features) from the given model"]},{"cell_type":"code","execution_count":null,"id":"6df1814f","metadata":{"cellId":"74ytwdlz36dnvpmvtpku5","id":"6df1814f"},"outputs":[],"source":["#!g1.1 #noqa\n","features = create_feature_extractor(model, return_nodes = ['2', '9', '12', '22', '29', '42'])"]},{"cell_type":"markdown","id":"a0cbcad4","metadata":{"cellId":"6ypq1787yo3mbowe3meau","execution_id":"e9e916a9-14c4-4029-87e2-d7c78972f5e0","id":"a0cbcad4"},"source":["For better understanding what is important for the model at each picked layer let's have a look at some of them."]},{"cell_type":"code","execution_count":null,"id":"3b462712","metadata":{"cellId":"bb7mtpqst5rhlqexo0x9x9","id":"3b462712"},"outputs":[],"source":["#!g1.1 #noqa\n","style_features = features(style.unsqueeze(0).detach())"]},{"cell_type":"code","execution_count":null,"id":"7438538f","metadata":{"cellId":"oklvn735fgil08l90jkc3","id":"7438538f"},"outputs":[],"source":["#!g1.1 #noqa\n","style_features['2'].shape"]},{"cell_type":"code","execution_count":null,"id":"d4262fd2","metadata":{"cellId":"zesv1zpvzok9tna4zpxwn","id":"d4262fd2"},"outputs":[],"source":["#!g1.1 #noqa\n","fig, ax = plt.subplots(8, 8, figsize=(30, 30))\n","\n","for i, f in enumerate(style_features['2'].squeeze()):\n","\n","    ax[i // 8][i % 8].imshow(f.detach().cpu().numpy())\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"0d826a8b","metadata":{"cellId":"34t0akohxbwds5fke5jps","id":"0d826a8b"},"outputs":[],"source":["#!g1.1 #noqa\n","with torch.no_grad():\n","    content_features = features(content.unsqueeze(0))"]},{"cell_type":"code","execution_count":null,"id":"3e676ea2","metadata":{"cellId":"q11alqp93wb9w8f67b5pih","id":"3e676ea2"},"outputs":[],"source":["#!g1.1 #noqa\n","fig, ax = plt.subplots(8, 8, figsize=(30, 30))\n","\n","for i, f in enumerate(content_features['2'].squeeze()[:64]):\n","\n","    ax[i // 8][i % 8].imshow(f.detach().cpu().numpy())\n","\n","plt.show()"]},{"cell_type":"markdown","id":"b03ca63b","metadata":{"cellId":"551mcl7wlggogqm5prumg","execution_id":"94d4e59c-4169-4d62-a4d3-2e735cf0cbc8","id":"b03ca63b"},"source":["### Metrics\n"]},{"cell_type":"code","execution_count":null,"id":"37358ab1","metadata":{"cellId":"omxzws8id5h689f6wzgode","id":"37358ab1"},"outputs":[],"source":["#!g1.1 #noqa\n","def gram_matrix(tensor: torch.tensor) -> torch.tensor:\n","    \"\"\"Calculate the gram matrix.\"\"\"\n","    _, d, h, w = tensor.size()  # first parameter is batch size, we don't need it\n","    tensor = tensor.view(d, h * w)\n","    gram = torch.mm(tensor, tensor.t())\n","\n","    return gram.div(d * h * w)"]},{"cell_type":"markdown","id":"001cb6ac","metadata":{"cellId":"xlsoeoc6t0h3goge886jq","execution_id":"e78211a2-0c4e-4f68-b979-fd44022c044d","id":"001cb6ac"},"source":["As style image is not changing during the training process, we can calculate its gram matrix just once and use it during the train."]},{"cell_type":"code","execution_count":null,"id":"8635b24f","metadata":{"cellId":"pd3lyeo34we6frc6qj6k99","id":"8635b24f"},"outputs":[],"source":["#!g1.1 #noqa\n","style_grams = {layer: gram_matrix(style_features[layer]).detach() for layer in style_features}"]},{"cell_type":"code","execution_count":null,"id":"c3c69c13","metadata":{"cellId":"zkq8an4zsyiydtc5ptjgmf","id":"c3c69c13"},"outputs":[],"source":["#!g1.1 #noqa\n","# Use content image as a target image\n","target = content.clone().requires_grad_(True).to(device)\n","\n","# Use random noise as a target image\n","# target = torch.rand(content.shape, requires_grad=True, device='cuda')"]},{"cell_type":"code","execution_count":null,"id":"6f057ae4","metadata":{"cellId":"9zxa3m082j0kztgom8386d","id":"6f057ae4"},"outputs":[],"source":["#!g1.1 #noqa\n","# Sets influence of each style layer to final loss\n","style_weights = {'2': 1,\n","                 '9': 0.9,\n","                 '12': 0.75,\n","                 '22': 0.2,\n","                 '29': 0.5,\n","                 '42': 0.2}\n","\n","content_weight = 1  # alpha\n","style_weight = 1e9  # beta"]},{"cell_type":"markdown","id":"b228068f","metadata":{"cellId":"v85k23mdwioki72mrp50a","execution_id":"b5802353-d23b-423f-bf45-8520d881a83e","id":"b228068f"},"source":["### Setup training process  "]},{"cell_type":"code","execution_count":null,"id":"9483940d","metadata":{"cellId":"ivl7vnwyy2cle9sfugg97","id":"9483940d"},"outputs":[],"source":["#!g1.1 #noqa\n","optimizer = optim.Adam([target], lr=0.05)\n","scheduler = StepLR(optimizer, step_size = 1000, gamma = 0.5)\n","loss_func = nn.L1Loss()\n","epochs = 2000"]},{"cell_type":"code","execution_count":null,"id":"190147a0","metadata":{"cellId":"26eb5lssir7juc2lam4rl2o","id":"190147a0"},"outputs":[],"source":["#!g1.1 #noqa\n","for eposh in range(epochs):\n","\n","    # gets the features from the target image\n","    target_img_features = features(target.unsqueeze(0))\n","\n","    # Calculates the content loss\n","    content_loss = loss_func(target_img_features['2'], content_features['2'])\n","\n","    # gets the style loss\n","    style_loss = 0\n","    for layer in style_weights:\n","        # gets the target image style representation at that layer\n","        target_img_feature = target_img_features[layer]\n","\n","        # calculates gram matrix for target image features at that layer\n","        target_img_gram = gram_matrix(target_img_feature)\n","\n","        # gets value of gram matrix for style image features at that layer\n","        style_gram = style_grams[layer]\n","\n","        # calculates weighted style loss for that layer\n","        style_loss += style_weights[layer] * loss_func(target_img_gram, style_gram)\n","\n","    # calculates the total loss\n","    loss = content_weight * content_loss + style_weight * style_loss\n","\n","    # updates target image\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    scheduler.step()\n","\n","    # displays intermediate images and the loss\n","    if (eposh + 1) % 1000 == 0:\n","        plt.title('Loss: {:.3f}'.format(loss.item()))\n","        plt.imshow(conv_to_img(target))\n","        plt.show()"]},{"cell_type":"markdown","id":"8e5413bc","metadata":{"cellId":"7zsxi62i23rosrke906e3c","execution_id":"c7e68ad8-2add-4a94-88f3-1280afeea3a6","id":"8e5413bc"},"source":["### Compare the results"]},{"cell_type":"code","execution_count":null,"id":"e207ab9b","metadata":{"cellId":"2ykyfamwjmftedw8rf5qqb","id":"e207ab9b"},"outputs":[],"source":["#!g1.1 #noqa\n","fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (25, 25))\n","\n","ax1.imshow(conv_to_img(content))\n","ax1.set_title('Content image')\n","ax2.imshow(conv_to_img(style))\n","ax2.set_title('Style image')\n","ax3.imshow(conv_to_img(target))\n","ax3.set_title('Target')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"b1256651","metadata":{"cellId":"cdwvxrmln3it45369a0bzo","id":"b1256651"},"outputs":[],"source":["#!g1.1 #noqa\n"]}],"metadata":{"colab":{"provenance":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"notebookId":"e9884db2-486c-4001-b4ba-85380f3da8d5","notebookPath":"TransferLearning/styleTransfer.ipynb"},"nbformat":4,"nbformat_minor":5}